#-------------------------------------------Data-----------------------------------------------
# 缓存模型相对training.conf 目录相对位置；
# 用于模型保存模型的断点重训，默认为空；
TRAINING_MODEL_RESUME="/home/niuzhibo/evaclip/PaddleMIX/output/checkpoint-500/"

# 集群训练数据相对training.conf 目录相对位置；
# 文本格式为 rand   cs  base64_image    unicode_caption;
DATAPATH="/home/niuzhibo/evaclip/data/"

# 训练数据条目数；
DATANUM=1000

# 训练地址下分part目录记录文件；
PART_PATH="/home/niuzhibo/evaclip/data/data_partstrain_split16.txt"

#--------------------------------------------Training-------------------------------------------------

#--------------------Distributed----------------
# 训练机器数量
TRAINERS_NUM=1

#
TRAINER_INSTANCES='127.0.0.1'
# TRAINER_INSTANCES='10.21.226.179,10.21.226.169'

# MASTER='10.21.226.179:8080'
MASTER='127.0.0.1:8080'

# 每台机器的GPU数量；
TRAINING_GPUS_PER_NODE=2

# 分布式并行设置，建议MP*SHARDING<=gpu_per_node, DP=node number
# 数据并行维度设置
DP_DEGREE=2

# 模型并行维度设置, 因为会切分模型，建议为2的N次方倍
MP_DEGREE=1

# sharding分组切片分布维度设置
SHARDING_DEGREE=1

# 单卡BS；
TRAINING_BS=64

#---------------------Base Set------------------

# 预加载Image-ERNIE模型相对training.conf 目录相对位置；
PRETRAINED_MODEL="/root/.paddlenlp/models/EVA/EVA02-CLIP-B-16/model_state.pdparams"

# 模型选择，evaclip创建模型
MODEL_NAME="EVA02-CLIP-B-16"
# MODEL_NAME="coca_EVA02-B-16"

OPTIMIZER="lamb"

TRAINING_WARM_UP_ITERS=0

TRAINING_EPOCHS=8

FP16_OPT_LEVEL="O1"

USE_AMP=False

# 学习率；
BASE_LR=5e-4

VISUAL_LR=2e-4

TEXT_LR=2e-5

#weight decay
BASE_WD=0.05

VISUAL_WD=0.05

TEXT_WD=0.05

#layer decay
BASE_LD=1.0

VISUAL_LD=0.75

TEXT_LD=0.75

BETA1=0.9

BETA2=0.999

EPSILON=1e-8

CLIP_GRAD=5.0

#--------------------------------------------Model-------------------------------------------------

# 训练输入图像大小；
TRAINING_IMAGE_SIZE=224

# 文本coding长度
TRAINING_CONTEXT_LENGTH=77

#--------------------------------------------Others-------------------------------------------------

# 训练时打印log频率；
TRAINING_PRINT_FREQUENCY=1

# 保存模型频率；
TRAINING_STEP_FREQUENCY=800

# 保存模型地址；
TRAINING_MODEL_PATH="../trained_model/paddle_ernie/${TASK_NAME}"

# 使用 python 版本，可执行文件选择
TRAINING_PYTHON="python"


