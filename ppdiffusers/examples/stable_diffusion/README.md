# Stable Diffusion

## 1. æ¨¡å‹ç®€ä»‹

Stable Diffusion æ˜¯ä¸€ä¸ªåŸºäº Latent Diffusion Modelsï¼ˆæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ŒLDMsï¼‰çš„æ–‡å›¾ç”Ÿæˆï¼ˆtext-to-imageï¼‰æ¨¡å‹ã€‚å…·ä½“æ¥è¯´ï¼Œå¾—ç›Šäº [Stability AI](https://stability.ai/) çš„è®¡ç®—èµ„æºæ”¯æŒå’Œ [LAION](https://laion.ai/) çš„æ•°æ®èµ„æºæ”¯æŒï¼ŒStable Diffusion åœ¨ [LAION-5B](https://laion.ai/blog/laion-5b/) çš„ä¸€ä¸ªå­é›†ä¸Šè®­ç»ƒäº†ä¸€ä¸ª Latent Diffusion Modelsï¼Œè¯¥æ¨¡å‹ä¸“é—¨ç”¨äºæ–‡å›¾ç”Ÿæˆã€‚Latent Diffusion Models é€šè¿‡åœ¨ä¸€ä¸ªæ½œåœ¨è¡¨ç¤ºç©ºé—´ä¸­è¿­ä»£â€œå»å™ªâ€æ•°æ®æ¥ç”Ÿæˆå›¾åƒï¼Œç„¶åå°†è¡¨ç¤ºç»“æœè§£ç ä¸ºå®Œæ•´çš„å›¾åƒï¼Œè®©æ–‡å›¾ç”Ÿæˆèƒ½å¤Ÿåœ¨æ¶ˆè´¹çº§ GPU ä¸Šï¼Œåœ¨10ç§’çº§åˆ«æ—¶é—´ç”Ÿæˆå›¾ç‰‡ï¼Œå¤§å¤§é™ä½äº†è½åœ°é—¨æ§›ï¼Œä¹Ÿå¸¦æ¥äº†æ–‡å›¾ç”Ÿæˆé¢†åŸŸçš„å¤§ç«ã€‚æ‰€ä»¥ï¼Œå¦‚æœä½ æƒ³äº†è§£ Stable Diffusion çš„èƒŒååŸç†ï¼Œå¯ä»¥å…ˆæ·±å…¥è§£è¯»ä¸€ä¸‹å…¶èƒŒåçš„è®ºæ–‡ [High-Resolution Image Synthesis with Latent Diffusion Models](https://ommer-lab.com/research/latent-diffusion-models/)ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šå…³äº Stable Diffusion æ¨¡å‹çš„ä¿¡æ¯ï¼Œä½ å¯ä»¥æŸ¥çœ‹ç”± ğŸ¤—Huggingface å›¢é˜Ÿæ’°å†™çš„ç›¸å…³[åšå®¢](https://huggingface.co/blog/stable_diffusion)ã€‚


<p align="center">
  <img src="https://github.com/CompVis/stable-diffusion/assets/50394665/268401d7-0a90-4a71-aba8-917949b63a2a" align="middle" width = "600" />
</p>
<p align="center">
  <img src="https://github.com/CompVis/latent-diffusion/assets/50394665/502f620b-900b-43c5-a970-9e1b884c3f32" align="middle" width = "600" />
</p>

æ³¨ï¼šæ¨¡å‹ç»“æ„å›¾å¼•è‡ª[CompVis/latent-diffusionä»“åº“](https://github.com/CompVis/latent-diffusion)ï¼Œç”Ÿæˆå›¾ç‰‡å¼•ç”¨è‡ª[CompVis/stable-diffusionä»“åº“](https://github.com/CompVis/stable-diffusion)ã€‚


### Stable Diffusion Model zoo

<div align="center">

| model name | params | weight |
|------------|:-------:|:------:|
| `CompVis/stable-diffusion-v1-4` | 0.98B |TODO |
| `runwayml/stable-diffusion-v1-5` | 0.98B |TODO |

</div>

- å½“å‰é¡µé¢ä»…æ”¯æŒä¸Šè¿°åŸºç¡€æ¨¡å‹çš„é¢„è®­ç»ƒï¼Œåç»­å°†é™†ç»­æ”¯æŒæ›´å¤šçš„Stable Diffusionæ¨¡å‹ã€‚
- æ¨¡å‹ä¸‹è½½åœ°å€ï¼šTODOï¼Œåç»­å°†æä¾› AI Studio ä¸Šé¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½åœ°å€ã€‚



## 2. ç¯å¢ƒå‡†å¤‡
é€šè¿‡ `git clone` å‘½ä»¤æ‹‰å– PaddleMIX æºç ï¼Œå¹¶å®‰è£…å¿…è¦çš„ä¾èµ–åº“ã€‚è¯·ç¡®ä¿ä½ çš„ PaddlePaddle æ¡†æ¶ç‰ˆæœ¬åœ¨ 2.5.2 ä¹‹åï¼ŒPaddlePaddle æ¡†æ¶å®‰è£…å¯å‚è€ƒ [é£æ¡¨å®˜ç½‘-å®‰è£…](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/linux-pip.html)ã€‚

```bash
# å…‹éš† PaddleMIX ä»“åº“
git clone https://github.com/PaddlePaddle/PaddleMIX

# å®‰è£…2.5.2ç‰ˆæœ¬çš„paddlepaddle-gpuï¼Œå½“å‰æˆ‘ä»¬é€‰æ‹©äº†cuda11.7çš„ç‰ˆæœ¬ï¼Œå¯ä»¥æŸ¥çœ‹ https://www.paddlepaddle.org.cn/ å¯»æ‰¾è‡ªå·±é€‚åˆçš„ç‰ˆæœ¬
python -m pip install paddlepaddle-gpu==2.5.2.post117 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html

# è¿›å…¥stable diffusionç›®å½•
cd PaddleMIX/ppdiffusers/examples/stable_diffusion

# å®‰è£…æ‰€éœ€çš„ä¾èµ–, å¦‚æœæç¤ºæƒé™ä¸å¤Ÿï¼Œè¯·åœ¨æœ€åå¢åŠ  --user é€‰é¡¹
pip install -r requirements.txt
```

> æ³¨ï¼šæœ¬æ¨¡å‹è®­ç»ƒä¸æ¨ç†éœ€è¦ä¾èµ– CUDA 11.2 åŠä»¥ä¸Šç‰ˆæœ¬ï¼Œå¦‚æœæœ¬åœ°æœºå™¨ä¸ç¬¦åˆè¦æ±‚ï¼Œå»ºè®®å‰å¾€ [AI Studio](https://aistudio.baidu.com/index) è¿›è¡Œæ¨¡å‹è®­ç»ƒã€æ¨ç†ä»»åŠ¡ã€‚

## 3. æ•°æ®å‡†å¤‡

é¢„è®­ç»ƒ Stable Diffusion ä½¿ç”¨ Laion400M æ•°æ®é›†ï¼Œéœ€è¦è‡ªè¡Œä¸‹è½½å’Œå¤„ç†ï¼Œå¤„ç†æ­¥éª¤è¯¦è§ 3.1è‡ªå®šä¹‰è®­ç»ƒæ•°æ®ã€‚æœ¬æ•™ç¨‹ä¸ºäº†æ–¹ä¾¿å¤§å®¶ **ä½“éªŒè·‘é€šè®­ç»ƒæµç¨‹**ï¼Œæœ¬æ•™ç¨‹æä¾›äº†å¤„ç†åçš„ Laion400M éƒ¨åˆ†æ•°æ®é›†ï¼Œå¯ç›´æ¥ä¸‹è½½è·å–ï¼Œè¯¦è§ 3.2ã€‚


### 3.1 è‡ªå®šä¹‰è®­ç»ƒæ•°æ®

å¦‚æœéœ€è¦è‡ªå®šä¹‰æ•°æ®ï¼Œæ¨èæ²¿ç”¨`coco_karpathy`æ•°æ®æ ¼å¼å¤„ç†è‡ªå·±çš„æ•°æ®ã€‚å…¶ä¸­æ¯æ¡æ•°æ®æ ‡æ³¨æ ¼å¼ç¤ºä¾‹ä¸º:
```text
{"caption": "A woman wearing a net on her head cutting a cake. ", "image": "val2014/COCO_val2014_000000522418.jpg", "image_id": "coco_522418"}
```

åœ¨å‡†å¤‡å¥½è‡ªå®šä¹‰æ•°æ®é›†ä»¥åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `create_pretraining_data.py` ç”Ÿæˆæˆ‘ä»¬éœ€è¦çš„æ•°æ®ã€‚

```bash
python create_pretraining_data.py \
    --input_path ./coco_data/coco_data.jsonl \
    --output_path ./processed_data \
    --caption_key "caption" \
    --image_key "image" \
    --per_part_file_num 1000 \
    --num_repeat 100 \
    --save_gzip_file
```

[create_pretraining_data.py](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/examples/stable_diffusion/create_pretraining_data.py) å¯ä¼ å…¥çš„å‚æ•°è§£é‡Šå¦‚ä¸‹ï¼š
* `--input_path`: è¾“å…¥çš„ jsonl æ–‡ä»¶è·¯å¾„ï¼Œå¯ä»¥æŸ¥çœ‹ `coco_data` æ–‡ä»¶å¤¹çš„ç»„ç»‡ç»“æ„ï¼Œè‡ªå®šä¹‰æˆ‘ä»¬è‡ªå·±çš„æ•°æ®ã€‚
* `--output_path`: å¤„ç†åçš„æ•°æ®ä¿å­˜è·¯å¾„ã€‚
* `--output_name`: è¾“å‡ºæ–‡ä»¶çš„åç§°ï¼Œé»˜è®¤ä¸º`custom_dataset`ã€‚
* `--caption_key`: jsonlæ–‡ä»¶ä¸­ï¼Œæ¯ä¸€è¡Œæ•°æ®è¡¨ç¤ºæ–‡æœ¬çš„ key å€¼ï¼Œé»˜è®¤ä¸º`caption`ã€‚
* `--image_key`: jsonlæ–‡ä»¶ä¸­ï¼Œæ¯ä¸€è¡Œæ•°æ®è¡¨ç¤ºå›¾ç‰‡çš„ key å€¼ï¼Œé»˜è®¤ä¸º`image`ã€‚
* `--per_part_file_num`: æ¯ä¸ªpartæ–‡ä»¶ä¿å­˜çš„æ•°æ®æ•°é‡ï¼Œé»˜è®¤ä¸º`1000`ã€‚
* `--save_gzip_file`: æ˜¯å¦å°†æ–‡ä»¶ä¿å­˜ä¸º`gzip`çš„æ ¼å¼ï¼Œé»˜è®¤ä¸º`False`ã€‚
* `--num_repeat`: `custom_dataset.filelist`æ–‡ä»¶ä¸­`partæ•°æ®`çš„é‡å¤æ¬¡æ•°ï¼Œé»˜è®¤ä¸º`1`ã€‚å½“å‰æˆ‘ä»¬è®¾ç½®æˆ`100`æ˜¯ä¸ºäº†èƒ½å¤Ÿåˆ¶é€ æ›´å¤šçš„`partæ•°æ®`ï¼Œå¯ä»¥é˜²æ­¢ç¨‹åºè¿è¡Œæ—¶ä¼šå¡ä½ï¼Œå¦‚æœç”¨æˆ·æœ‰å¾ˆå¤šæ•°æ®çš„æ—¶å€™ï¼Œå¯ä»¥æ— ä¿®æ”¹è¯¥é»˜è®¤å€¼ã€‚

è¿è¡Œä¸Šè¿°å‘½ä»¤åï¼Œä¼šç”Ÿæˆ `./processed_data` æ–‡ä»¶å¤¹ã€‚
```
processed_data
â”œâ”€â”€ filelist
|   â”œâ”€â”€ custom_dataset.filelist.list
|   â””â”€â”€ custom_dataset.filelist
â””â”€â”€ laion400m_format_data
    â””â”€â”€ part-000001.gz
```

`processed_data/custom_dataset.filelist` æ˜¯æ•°æ®ç´¢å¼•æ–‡ä»¶ï¼ŒåŒ…å«100è¡Œæ•°æ®ï¼Œæ¯è¡Œéƒ½ä»£è¡¨ä¸€ä¸ªæ•°æ®æ–‡ä»¶çš„è·¯å¾„ã€‚è¯·ç¡®ä¿è¯¥æ–‡ä»¶çš„è¡Œæ•°è¶³å¤Ÿå¤šï¼Œä»¥é˜²æ­¢åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°å¡é¡¿ï¼Œå†…å®¹å¦‚ä¸‹æ‰€ç¤ºï¼š
```
processed_data/laion400m_format_data/part-000001.gz
processed_data/laion400m_format_data/part-000001.gz
processed_data/laion400m_format_data/part-000001.gz
processed_data/laion400m_format_data/part-000001.gz
processed_data/laion400m_format_data/part-000001.gz
processed_data/laion400m_format_data/part-000001.gz
processed_data/laion400m_format_data/part-000001.gz
processed_data/laion400m_format_data/part-000001.gz
...
```
`processed_data/custom_dataset.filelist.list` ä¸ºfilelistç´¢å¼•æ–‡ä»¶ï¼Œå†…å®¹å¦‚ä¸‹æ‰€ç¤ºï¼š
```
processed_data/filelist/custom_dataset.filelist
```
`processed_data/laion400m_format_data/part-000001.gz` ä¸ºå®é™…çš„æ•°æ®æ–‡ä»¶ï¼Œå†…å®¹ç»“æ„å¦‚ä¸‹æ‰€ç¤ºï¼š

æ¯ä¸€è¡Œä»¥`"\t"`è¿›è¡Œåˆ†å‰²ï¼Œç¬¬ä¸€åˆ—ä¸º `captionæ–‡æœ¬æè¿°`, ç¬¬äºŒåˆ—ä¸º `å ä½ç¬¦ç©º`, ç¬¬ä¸‰åˆ—ä¸º `base64ç¼–ç çš„å›¾ç‰‡`ï¼Œç¤ºä¾‹ï¼š`caption, _, img_b64 = vec[:3]`


### 3.2 Laion400M Demo æ•°æ®é›†ï¼ˆéƒ¨åˆ†æ•°æ®ï¼Œçº¦1000æ¡ï¼Œä»…ä¾›éªŒè¯è·‘é€šè®­ç»ƒï¼‰

demo æ•°æ®å¯é€šè¿‡å¦‚ä¸‹å‘½ä»¤ä¸‹è½½ä¸è§£å‹ï¼š

```bash
# åˆ é™¤å½“å‰ç›®å½•ä¸‹çš„data
rm -rf data
# ä¸‹è½½ laion400m_demo æ•°æ®é›†
wget https://paddlenlp.bj.bcebos.com/models/community/junnyu/develop/laion400m_demo_data.tar.gz
# è§£å‹
tar -zxvf laion400m_demo_data.tar.gz
```

è§£å‹åæ–‡ä»¶ç›®å½•å¦‚ä¸‹æ‰€ç¤ºï¼š
```
data
â”œâ”€â”€ filelist
|   â”œâ”€â”€ train.filelist.list
|   â””â”€â”€ laion400m_en.filelist
â”œâ”€â”€ laion400m_new
|   â””â”€â”€ part-00001.gz
â””â”€â”€ laion400m_demo_data.tar.gz # å¤šä½™çš„å‹ç¼©åŒ…ï¼Œå¯ä»¥åˆ é™¤
```

`laion400m_en.filelist` æ˜¯æ•°æ®ç´¢å¼•æ–‡ä»¶ï¼ŒåŒ…å«äº†6000è¡Œæ•°æ®æ–‡ä»¶çš„è·¯å¾„ï¼ˆpart-00001.gz ä»…ä¸ºéƒ¨åˆ†æ•°æ®ï¼‰ï¼Œå†…å®¹å¦‚ä¸‹æ‰€ç¤ºï¼š
```
./data/laion400m_new/part-00001.gz
./data/laion400m_new/part-00001.gz
./data/laion400m_new/part-00001.gz
./data/laion400m_new/part-00001.gz
./data/laion400m_new/part-00001.gz
./data/laion400m_new/part-00001.gz
./data/laion400m_new/part-00001.gz
...
```

## 4. è®­ç»ƒ

Stable Diffusion æ¨¡å‹åŒ…å« 3 ä¸ªç»„æˆéƒ¨åˆ†ï¼švaeã€text_encoderã€unetï¼Œå…¶ä¸­é¢„è®­ç»ƒä»…éœ€éšæœºåˆå§‹åŒ– unet éƒ¨åˆ†ï¼Œå…¶ä½™éƒ¨åˆ†å¯ç›´æ¥åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œæœ¬æ•™ç¨‹ä¸­æˆ‘ä»¬åŠ è½½ `CompVis/stable-diffusion-v1-4` ä¸­çš„é¢„è®­ç»ƒå¥½çš„ `vae` ä»¥åŠ`text_encoder` æƒé‡ï¼Œéšæœºåˆå§‹åŒ–äº† `unet` æ¨¡å‹æƒé‡ã€‚

### 4.1 ç¡¬ä»¶è¦æ±‚

ç¤ºä¾‹è„šæœ¬é…ç½®åœ¨æ˜¾å­˜ â‰¥40GB çš„æ˜¾å¡ä¸Šå¯æ­£å¸¸è®­ç»ƒï¼Œå¦‚æ˜¾å­˜ä¸æ»¡è¶³è¦æ±‚ï¼Œå¯é€šè¿‡ä¿®æ”¹å‚æ•°çš„æ–¹å¼è¿è¡Œè„šæœ¬ï¼š
- å¦‚æœæœ¬åœ°ç¯å¢ƒæ˜¾å­˜ä¸å¤Ÿï¼Œè¯·ä½¿ç”¨ AIStudio ä¸Š 32G æ˜¾å­˜çš„ GPU ç¯å¢ƒï¼Œå¹¶ä¿®æ”¹ `--per_device_train_batch_size` ä¸º 32ã€‚
- bf16 æ··åˆç²¾åº¦è®­ç»ƒæ¨¡å¼æ”¯æŒ A100ã€3090ã€3080 ç­‰ç¡¬ä»¶ï¼Œä¸æ”¯æŒä½¿ç”¨ V100 è¿›è¡Œè®­ç»ƒï¼Œå¦‚æœä½ çš„ç¡¬ä»¶æ»¡è¶³è¦æ±‚ï¼Œä¿®æ”¹ `--bf16` ä¸º `True` å¯å¯åŠ¨æ··åˆç²¾åº¦è®­ç»ƒæ¨¡å¼ï¼Œä½“éªŒæ›´å¿«é€Ÿçš„è®­ç»ƒã€‚

### 4.2 å•æœºå•å¡è®­ç»ƒ

> æ³¨æ„ï¼Œæˆ‘ä»¬å½“å‰è®­ç»ƒçš„åˆ†è¾¨ç‡æ˜¯ `256x256` ï¼Œå¦‚æœéœ€è¦è®­ç»ƒ `512x512` åˆ†è¾¨ç‡ï¼Œè¯·ä¿®æ”¹ `--resolution` ä¸º 512 å¹¶ä¸”é™ä½`--per_device_train_batch_size` å‚æ•°ï¼Œå¦åˆ™ä¼šæŠ¥æ˜¾å­˜ä¸è¶³çš„é”™è¯¯ã€‚

å•æœºå•å¡è®­ç»ƒå¯åŠ¨è„šæœ¬å¦‚ä¸‹ï¼Œå»ºè®®ä¿å­˜ä¸º `train.sh` åæ‰§è¡Œå‘½ä»¤ `sh train.sh`ï¼š

```bash
export FLAG_FUSED_LINEAR=0
export FLAGS_conv_workspace_size_limit=4096
# æ˜¯å¦å¼€å¯ ema
export FLAG_USE_EMA=0
# æ˜¯å¦å¼€å¯ recompute
export FLAG_RECOMPUTE=1
# æ˜¯å¦å¼€å¯ xformers
export FLAG_XFORMERS=1

# å¦‚æœä½¿ç”¨è‡ªå®šä¹‰æ•°æ®
FILE_LIST=./processed_data/filelist/custom_dataset.filelist.list
# å¦‚æœä½¿ç”¨laion400m_demoæ•°æ®é›†ï¼Œéœ€è¦æŠŠä¸‹é¢çš„æ³¨é‡Šå–æ¶ˆ
# FILE_LIST=./data/filelist/train.filelist.list

python -u train_txt2img_laion400m_trainer.py \
    --do_train \
    --output_dir ./laion400m_pretrain_output_trainer \
    --per_device_train_batch_size 32 \
    --gradient_accumulation_steps 1 \
    --learning_rate 1e-4 \
    --weight_decay 0.01 \
    --max_steps 200000 \
    --lr_scheduler_type "constant" \
    --warmup_steps 0 \
    --image_logging_steps 1000 \
    --logging_steps 10 \
    --resolution 256 \
    --save_steps 10000 \
    --save_total_limit 20 \
    --seed 23 \
    --dataloader_num_workers 4 \
    --vae_name_or_path CompVis/stable-diffusion-v1-4/vae \
    --text_encoder_name_or_path CompVis/stable-diffusion-v1-4/text_encoder \
    --unet_name_or_path ./sd/unet_config.json \
    --file_list ${FILE_LIST} \
    --model_max_length 77 \
    --max_grad_norm -1 \
    --disable_tqdm True \
    --bf16 False
```

[train_txt2img_laion400m_trainer.py](https://github.com/PaddlePaddle/PaddleMIX/blob/develop/ppdiffusers/examples/stable_diffusion/train_txt2img_laion400m_trainer.py) å¯ä¼ å…¥çš„å‚æ•°è§£é‡Šå¦‚ä¸‹ï¼š
* `--vae_name_or_path`: é¢„è®­ç»ƒ `vae` æ¨¡å‹åç§°æˆ–åœ°å€ï¼Œ`CompVis/stable-diffusion-v1-4/vae`ä¸º`kl-8.ckpt` ï¼Œç¨‹åºå°†è‡ªåŠ¨ä» BOS ä¸Šä¸‹è½½é¢„è®­ç»ƒå¥½çš„æƒé‡ï¼Œé»˜è®¤å€¼ä¸º `None`ã€‚
* `--text_encoder_name_or_path`: é¢„è®­ç»ƒ `text_encoder` æ¨¡å‹åç§°æˆ–åœ°å€ï¼Œå½“å‰ä»…æ”¯æŒ `CLIPTextModel`ï¼Œé»˜è®¤å€¼ä¸º `None`ã€‚
* `--unet_name_or_path`: é¢„è®­ç»ƒ `unet` æ¨¡å‹åç§°æˆ–åœ°å€ï¼Œé»˜è®¤å€¼ä¸º `None`ã€‚
* `--pretrained_model_name_or_path`: åŠ è½½é¢„è®­ç»ƒæ¨¡å‹çš„åç§°æˆ–æœ¬åœ°è·¯å¾„ï¼Œå¦‚ `CompVis/stable-diffusion-v1-4`ï¼Œ`vae_name_or_path`ï¼Œ`text_encoder_name_or_path` å’Œ `unet_name_or_path` çš„ä¼˜å…ˆçº§é«˜äº `pretrained_model_name_or_path`ã€‚
* `--per_device_train_batch_size`: è®­ç»ƒæ—¶æ¯å¼ æ˜¾å¡æ‰€ä½¿ç”¨çš„ `batch_sizeæ‰¹é‡`ï¼Œå½“æˆ‘ä»¬çš„æ˜¾å­˜è¾ƒå°çš„æ—¶å€™ï¼Œéœ€è¦å°†è¿™ä¸ªå€¼è®¾ç½®çš„å°ä¸€ç‚¹ã€‚
* `--gradient_accumulation_steps`: æ¢¯åº¦ç´¯ç§¯çš„æ­¥æ•°ï¼Œç”¨æˆ·å¯ä»¥æŒ‡å®šæ¢¯åº¦ç´¯ç§¯çš„æ­¥æ•°ï¼Œåœ¨æ¢¯åº¦ç´¯ç§¯çš„ step ä¸­ã€‚å‡å°‘å¤šå¡ä¹‹é—´æ¢¯åº¦çš„é€šä¿¡ï¼Œå‡å°‘æ›´æ–°çš„æ¬¡æ•°ï¼Œæ‰©å¤§è®­ç»ƒçš„ batch_sizeã€‚
* `--learning_rate`: å­¦ä¹ ç‡ã€‚
* `--unet_learning_rate`: `unet` çš„å­¦ä¹ ç‡ï¼Œè¿™é‡Œçš„å­¦ä¹ ç‡ä¼˜å…ˆçº§å°†ä¼šé«˜äº `learning_rate`ï¼Œé»˜è®¤å€¼ä¸º `None`ã€‚
* `--train_text_encoder`: æ˜¯å¦åŒæ—¶è®­ç»ƒ `text_encoder`ï¼Œé»˜è®¤å€¼ä¸º `False`ã€‚
* `--text_encoder_learning_rate`: `text_encoder` çš„å­¦ä¹ ç‡ï¼Œé»˜è®¤å€¼ä¸º `None`ã€‚
* `--weight_decay`: AdamW ä¼˜åŒ–å™¨çš„ `weight_decay`ã€‚
* `--max_steps`: æœ€å¤§çš„è®­ç»ƒæ­¥æ•°ã€‚
* `--save_steps`: æ¯é—´éš”å¤šå°‘æ­¥ `ï¼ˆglobal stepæ­¥æ•°ï¼‰`ï¼Œä¿å­˜æ¨¡å‹ã€‚
* `--save_total_limit`: æœ€å¤šä¿å­˜å¤šå°‘ä¸ªæ¨¡å‹ã€‚
* `--lr_scheduler_type`: è¦ä½¿ç”¨çš„å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥ã€‚é»˜è®¤ä¸º `constant`ã€‚
* `--warmup_steps`: ç”¨äºä» 0 åˆ° `learning_rate` çš„çº¿æ€§ warmup çš„æ­¥æ•°ã€‚
* `--resolution`: é¢„è®­ç»ƒé˜¶æ®µå°†è®­ç»ƒçš„å›¾åƒçš„åˆ†è¾¨ç‡ï¼Œé»˜è®¤ä¸º `512`ã€‚
* `--noise_offset`: é¢„è®­ç»ƒé˜¶æ®µç”Ÿæˆæ“ä½œæ—¶çš„åç§»é‡ï¼Œé»˜è®¤ä¸º `0`ã€‚
* `--snr_gamma`: å¹³è¡¡æŸå¤±æ—¶ä½¿ç”¨çš„ SNR åŠ æƒ gamma å€¼ã€‚å»ºè®®ä¸º`5.0`ï¼Œé»˜è®¤ä¸º `None`ã€‚æ›´å¤šç»†èŠ‚åœ¨è¿™é‡Œï¼šhttps://arxiv.org/abs/2303.09556 ã€‚
* `--input_perturbation`: è¾“å…¥æ‰°åŠ¨çš„å°ºåº¦ï¼Œæ¨èä¸º `0.1`ï¼Œé»˜è®¤å€¼ä¸º `0`ã€‚
* `--image_logging_steps`: æ¯éš”å¤šå°‘æ­¥ï¼Œlog è®­ç»ƒè¿‡ç¨‹ä¸­çš„å›¾ç‰‡ï¼Œé»˜è®¤ä¸º `1000` æ­¥ï¼Œæ³¨æ„ `image_logging_steps` éœ€è¦æ˜¯ `logging_steps` çš„æ•´æ•°å€ã€‚
* `--logging_steps`: logging æ—¥å¿—çš„æ­¥æ•°ï¼Œé»˜è®¤ä¸º `50` æ­¥ã€‚
* `--output_dir`: æ¨¡å‹ä¿å­˜è·¯å¾„ã€‚
* `--seed`: éšæœºç§å­ï¼Œä¸ºäº†å¯ä»¥å¤ç°è®­ç»ƒç»“æœï¼ŒTipsï¼šå½“å‰ paddle è®¾ç½®è¯¥éšæœºç§å­åä»æ— æ³•å®Œç¾å¤ç°ã€‚
* `--dataloader_num_workers`: Dataloader æ‰€ä½¿ç”¨çš„ `num_workers` å‚æ•°ï¼Œè¯·ç¡®ä¿å¤„ç†åçš„`partæ–‡ä»¶`æ•°é‡è¦å¤§äºç­‰äº`dataloader_num_workers` * `num_gpus`ï¼Œå¦åˆ™ç¨‹åºä¼šå¡ä½ï¼Œä¾‹å¦‚ï¼š`dataloader_num_workers=4`ã€`num_gpus=2`æ—¶å€™ï¼Œè¯·ç¡®ä¿åˆ‡åˆ†åçš„`partæ–‡ä»¶`æ•°é‡è¦å¤§äºç­‰äº`8`ã€‚
* `--file_list`: file_list æ–‡ä»¶åœ°å€ã€‚
* `--num_inference_steps`: æ¨ç†é¢„æµ‹æ—¶å€™ä½¿ç”¨çš„æ­¥æ•°ã€‚
* `--model_max_length`: `tokenizer` ä¸­çš„ `model_max_length` å‚æ•°ï¼Œè¶…è¿‡è¯¥é•¿åº¦å°†ä¼šè¢«æˆªæ–­ã€‚
* `--tokenizer_name`: æˆ‘ä»¬éœ€è¦ä½¿ç”¨çš„ `tokenizer_name`ã€‚
* `--prediction_type`: é¢„æµ‹ç±»å‹ï¼Œå¯ä» `["epsilon", "v_prediction"]` é€‰æ‹©ã€‚
* `--use_ema`: æ˜¯å¦å¯¹ `unet` ä½¿ç”¨ `ema`ï¼Œé»˜è®¤ä¸º `False`ã€‚
* `--max_grad_norm`: æ¢¯åº¦å‰ªè£çš„æœ€å¤§ norm å€¼ï¼Œ`-1` è¡¨ç¤ºä¸ä½¿ç”¨æ¢¯åº¦è£å‰ªç­–ç•¥ã€‚
* `--recompute`: æ˜¯å¦å¼€å¯é‡è®¡ç®—ï¼Œ(`bool`ï¼Œå¯é€‰ï¼Œé»˜è®¤ä¸º `False`)ï¼Œåœ¨å¼€å¯åæˆ‘ä»¬å¯ä»¥å¢å¤§ batch_sizeï¼Œæ³¨æ„åœ¨å° batch_size çš„æ¡ä»¶ä¸‹ï¼Œå¼€å¯ recompute åæ˜¾å­˜å˜åŒ–ä¸æ˜æ˜¾ï¼Œåªæœ‰å½“å¼€å¤§ batch_size åæ‰èƒ½æ˜æ˜¾æ„Ÿå—åˆ°åŒºåˆ«ã€‚
* `--bf16`: æ˜¯å¦ä½¿ç”¨ bf16 æ··åˆç²¾åº¦æ¨¡å¼è®­ç»ƒï¼Œé»˜è®¤æ˜¯ fp32 è®­ç»ƒã€‚(`bool`ï¼Œå¯é€‰ï¼Œé»˜è®¤ä¸º `False`)
* `--fp16`: æ˜¯å¦ä½¿ç”¨ fp16 æ··åˆç²¾åº¦æ¨¡å¼è®­ç»ƒï¼Œé»˜è®¤æ˜¯ fp32 è®­ç»ƒã€‚(`bool`ï¼Œå¯é€‰ï¼Œé»˜è®¤ä¸º `False`)
* `--fp16_opt_level`: æ··åˆç²¾åº¦è®­ç»ƒæ¨¡å¼ï¼Œå¯ä¸º ``O1`` æˆ– ``O2`` æ¨¡å¼ï¼Œé»˜è®¤ ``O1`` æ¨¡å¼ï¼Œé»˜è®¤ ``O1`` åªåœ¨ fp16 é€‰é¡¹å¼€å¯æ—¶å€™ç”Ÿæ•ˆã€‚
* `--enable_xformers_memory_efficient_attention`: æ˜¯å¦å¼€å¯ `xformers`ï¼Œå¼€å¯åè®­ç»ƒé€Ÿåº¦ä¼šå˜æ…¢ï¼Œä½†æ˜¯èƒ½å¤ŸèŠ‚çœæ˜¾å­˜ã€‚æ³¨æ„æˆ‘ä»¬éœ€è¦å®‰è£…å¤§äºç­‰äº 2.5.2 ç‰ˆæœ¬çš„ paddlepaddleï¼
* `--only_save_updated_model`: æ˜¯å¦ä»…ä¿å­˜ç»è¿‡è®­ç»ƒçš„æƒé‡ï¼Œæ¯”å¦‚ä¿å­˜ `unet`ã€`ema ç‰ˆ unet`ã€`text_encoder`ï¼Œé»˜è®¤å€¼ä¸º `True`ã€‚


### 4.3 å•æœºå¤šå¡è®­ç»ƒ
```bash
export FLAG_FUSED_LINEAR=0
export FLAGS_conv_workspace_size_limit=4096
# æ˜¯å¦å¼€å¯ ema
export FLAG_USE_EMA=0
# æ˜¯å¦å¼€å¯ recompute
export FLAG_RECOMPUTE=1
# æ˜¯å¦å¼€å¯ xformers
export FLAG_XFORMERS=1

# å¦‚æœä½¿ç”¨è‡ªå®šä¹‰æ•°æ®
FILE_LIST=./processed_data/filelist/custom_dataset.filelist.list
# å¦‚æœä½¿ç”¨laion400m_demoæ•°æ®é›†ï¼Œéœ€è¦æŠŠä¸‹é¢çš„æ³¨é‡Šå–æ¶ˆ
# FILE_LIST=./data/filelist/train.filelist.list

python -u -m paddle.distributed.launch --gpus "0,1,2,3,4,5,6,7" train_txt2img_laion400m_trainer.py \
    --do_train \
    --output_dir ./laion400m_pretrain_output_trainer \
    --per_device_train_batch_size 32 \
    --gradient_accumulation_steps 1 \
    --learning_rate 1e-4 \
    --weight_decay 0.01 \
    --max_steps 200000 \
    --lr_scheduler_type "constant" \
    --warmup_steps 0 \
    --image_logging_steps 1000 \
    --logging_steps 10 \
    --resolution 256 \
    --save_steps 10000 \
    --save_total_limit 20 \
    --seed 23 \
    --dataloader_num_workers 4 \
    --vae_name_or_path CompVis/stable-diffusion-v1-4/vae \
    --text_encoder_name_or_path CompVis/stable-diffusion-v1-4/text_encoder \
    --unet_name_or_path ./unet_config.json \
    --file_list ${FILE_LIST} \
    --model_max_length 77 \
    --max_grad_norm -1 \
    --disable_tqdm True \
    --bf16 False
```

### 4.4 å¤šæœºå¤šå¡è®­ç»ƒ

éœ€åœ¨ `paddle.distributed.launch` åå¢åŠ å‚æ•° `--ips IP1,IP2,IP3,IP4`ï¼Œåˆ†åˆ«å¯¹åº”å¤šå°æœºå™¨çš„ IPï¼Œæ›´å¤šä¿¡æ¯å¯å‚è€ƒ [é£æ¡¨å®˜ç½‘-åˆ†å¸ƒå¼è®­ç»ƒ](https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/guides/06_distributed_training/cluster_quick_start_collective_cn.html)ã€‚

## 5. æ¨¡å‹æ¨ç†

è¯·å°†ä¸‹é¢çš„ä»£ç ä¿å­˜åˆ° eval.py ä¸­å¹¶è¿è¡Œã€‚ä½ å¯ä»¥é€‰æ‹©ç›´æ¥åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡å®Œæˆæ¨ç†ï¼Œå…·ä½“åšæ³•å‚è€ƒ 5.1ã€‚å¦‚æœä½ ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®å®Œæˆäº†æ¨¡å‹è®­ç»ƒå¹¶ä¿å­˜äº† checkpointï¼Œä½ å¯ä»¥é€‰æ‹©åŠ è½½è‡ªè¡Œè®­ç»ƒçš„æ¨¡å‹å‚æ•°è¿›è¡Œæ¨ç†ï¼Œå…·ä½“åšæ³•å‚è€ƒ 5.2ã€‚

### 5.1 ç›´æ¥åŠ è½½æ¨¡å‹å‚æ•°æ¨ç†

æœªç»å®Œæ•´è®­ç»ƒï¼Œç›´æ¥åŠ è½½å…¬å¼€å‘å¸ƒçš„æ¨¡å‹å‚æ•°è¿›è¡Œæ¨ç†ã€‚

```python
from ppdiffusers import StableDiffusionPipeline, UNet2DConditionModel
# åŠ è½½å…¬å¼€å‘å¸ƒçš„ unet æƒé‡
unet_model_name_or_path = "CompVis/stable-diffusion-v1-4/unet"
unet = UNet2DConditionModel.from_pretrained(unet_model_name_or_path)
pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", safety_checker=None, unet=unet)
prompt = "a photo of an astronaut riding a horse on mars"  # or a little girl dances in the cherry blossom rain
image = pipe(prompt, guidance_scale=7.5, width=512, height=512).images[0]
image.save("astronaut_rides_horse.png")
```


### 5.2 ä½¿ç”¨è®­ç»ƒçš„æ¨¡å‹å‚æ•°è¿›è¡Œæ¨ç†

å¾…æ¨¡å‹è®­ç»ƒå®Œæ¯•ï¼Œä¼šåœ¨ `output_dir` ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ï¼Œä½¿ç”¨è‡ªè¡Œè®­ç»ƒåç”Ÿæˆçš„æ¨¡å‹å‚æ•°è¿›è¡Œæ¨ç†ã€‚

```python
from ppdiffusers import StableDiffusionPipeline, UNet2DConditionModel
# åŠ è½½ä¸Šé¢æˆ‘ä»¬è®­ç»ƒå¥½çš„ unet æƒé‡
unet_model_name_or_path = "./laion400m_pretrain_output_trainer/checkpoint-5000/unet"
unet = UNet2DConditionModel.from_pretrained(unet_model_name_or_path)
pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", safety_checker=None, unet=unet)
prompt = "a photo of an astronaut riding a horse on mars"
# å½“å‰è®­ç»ƒçš„æ˜¯256x256åˆ†è¾¨ç‡å›¾ç‰‡,å› æ­¤è¯·ç¡®ä¿è®­ç»ƒå’Œæ¨ç†å‚æ•°æœ€å¥½ä¸€è‡´
image = pipe(prompt, guidance_scale=7.5, width=256, height=256).images[0]
image.save("astronaut_rides_horse.png")
```

## 6. å‚è€ƒèµ„æ–™
- https://github.com/CompVis/latent-diffusion
- https://github.com/CompVis/stable-diffusion
