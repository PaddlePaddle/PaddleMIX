# Stable Diffusion XL å¾®è°ƒ

`train_text_to_image_sdxl.py` è„šæœ¬å±•ç¤ºäº†å¦‚ä½•åœ¨ä½ è‡ªå·±çš„æ•°æ®é›†ä¸Šå¾®è°ƒ Stable Diffusion XL (SDXL) æ¨¡å‹ã€‚

ğŸš¨ è¿™ä¸ªè„šæœ¬æ˜¯å®éªŒæ€§çš„ã€‚è„šæœ¬ä¼šå¾®è°ƒæ•´ä¸ªæ¨¡å‹ï¼Œè€Œä¸”å¾ˆå¤šæ—¶å€™æ¨¡å‹ä¼šè¿‡æ‹Ÿåˆï¼Œå¹¶é‡åˆ°åƒç¾éš¾æ€§é—å¿˜è¿™æ ·çš„é—®é¢˜ã€‚å»ºè®®å°è¯•ä¸åŒçš„è¶…å‚æ•°ä»¥è·å¾—æœ€ä½³ç»“æœã€‚ğŸš¨

## æœ¬åœ°è¿è¡Œ

### å®‰è£…ä¾èµ–é¡¹

åœ¨è¿è¡Œè„šæœ¬ä¹‹å‰ï¼Œç¡®ä¿å®‰è£…äº†åº“çš„è®­ç»ƒä¾èµ–é¡¹ï¼š

**é‡è¦**

ä¸ºäº†ç¡®ä¿ä½ èƒ½æˆåŠŸè¿è¡Œæœ€æ–°ç‰ˆæœ¬çš„ç¤ºä¾‹è„šæœ¬ï¼Œæˆ‘ä»¬å¼ºçƒˆæ¨è **ä»æºä»£ç å®‰è£…** å¹¶ä¿æŒå®‰è£…æ˜¯æœ€æ–°çš„ï¼Œå› ä¸ºæˆ‘ä»¬ç»å¸¸æ›´æ–°ç¤ºä¾‹è„šæœ¬å¹¶å®‰è£…ä¸€äº›ç‰¹å®šäºç¤ºä¾‹çš„è¦æ±‚ã€‚ä¸ºæ­¤ï¼Œæ‰§è¡Œä»¥ä¸‹æ­¥éª¤åœ¨ä¸€ä¸ªæ–°çš„è™šæ‹Ÿç¯å¢ƒä¸­ï¼š

```bash
git clone https://github.com/PaddlePaddle/PaddleMIX.git
cd PaddleMIX/ppdiffusers
pip install -e .
```

ç„¶åè¿›å…¥ `examples/text_to_image` æ–‡ä»¶å¤¹å¹¶è¿è¡Œ
```bash
pip install -r requirements_sdxl.txt
```


### è®­ç»ƒ

```bash
export MODEL_NAME="stabilityai/stable-diffusion-xl-base-1.0"
export VAE_NAME="madebyollin/sdxl-vae-fp16-fix"
export DATASET_NAME="lambdalabs/naruto-blip-captions"

export HF_ENDPOINT=https://hf-mirror.com
export FLAGS_conv_workspace_size_limit=4096


python -u train_text_to_image_sdxl.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --pretrained_vae_model_name_or_path=$VAE_NAME \
  --dataset_name=$DATASET_NAME \
  --enable_xformers_memory_efficient_attention \
  --resolution=512 --center_crop --random_flip \
  --proportion_empty_prompts=0.2 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 --gradient_checkpointing \
  --max_train_steps=10000 \
  --learning_rate=1e-06 --lr_scheduler="constant" --lr_warmup_steps=0 \
  --mixed_precision="fp16" \
  --report_to="wandb" \
  --validation_prompt="a cute Sundar Pichai creature" --validation_epochs 5 \
  --checkpointing_steps=5000 \
  --output_dir="sdxl-pokemon-model"
```

**æ³¨é‡Š**ï¼š

* `train_text_to_image_sdxl.py` è„šæœ¬ä¼šé¢„è®¡ç®—æ–‡æœ¬åµŒå…¥å’ŒVAEç¼–ç ï¼Œå¹¶å°†å®ƒä»¬ä¿å­˜åœ¨å†…å­˜ä¸­ã€‚å¯¹äºåƒ [`lambdalabs/naruto-blip-captions`](https://hf.co/datasets/lambdalabs/naruto-blip-captions) è¿™æ ·çš„å°æ•°æ®é›†æ¥è¯´ï¼Œè¿™å¯èƒ½ä¸æ˜¯é—®é¢˜ï¼Œä½†å½“è„šæœ¬ç”¨äºæ›´å¤§çš„æ•°æ®é›†æ—¶ï¼Œè‚¯å®šä¼šå¯¼è‡´å†…å­˜é—®é¢˜ã€‚å¯¹äºè¿™äº›æƒ…å†µï¼Œä½ å¯èƒ½ä¼šå¸Œæœ›å°†è¿™äº›é¢„è®¡ç®—çš„è¡¨ç¤ºåºåˆ—åŒ–åˆ°ç£ç›˜ä¸Šï¼Œå¹¶åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­åŠ è½½å®ƒä»¬ã€‚æœ‰å…³æ›´æ·±å…¥çš„è®¨è®ºï¼Œè¯·å‚é˜… [è¿™ä¸ª PR](https://github.com/huggingface/diffusers/pull/4505)ã€‚
* è®­ç»ƒè„šæœ¬æ˜¯è®¡ç®—å¯†é›†å‹çš„ï¼Œå¯èƒ½æ— æ³•åœ¨æ¶ˆè´¹çº§GPUä¸Šè¿è¡Œï¼Œæ¯”å¦‚ Tesla T4ã€‚
* ä¸Šé¢æ˜¾ç¤ºçš„è®­ç»ƒå‘½ä»¤åœ¨è®­ç»ƒå‘¨æœŸä¹‹é—´æ‰§è¡Œä¸­é—´è´¨é‡éªŒè¯ï¼Œå¹¶å°†ç»“æœè®°å½•åˆ° Weights and Biasesã€‚`--report_to`ã€`--validation_prompt` å’Œ `--validation_epochs` æ˜¯è¿™é‡Œç›¸å…³çš„ CLI å‚æ•°ã€‚
* ä¼—æ‰€å‘¨çŸ¥ï¼ŒSDXLçš„VAEå­˜åœ¨æ•°å€¼ä¸ç¨³å®šæ€§é—®é¢˜ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬è¿˜æš´éœ²äº†ä¸€ä¸ª CLI å‚æ•°ï¼Œå³ `--pretrained_vae_model_name_or_path`ï¼Œè®©ä½ æŒ‡å®šæ›´å¥½çš„VAEçš„ä½ç½®ï¼ˆä¾‹å¦‚[è¿™ä¸ª](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)ï¼‰ã€‚
* ä¸æ”¯æŒ`--use_8bit_adam`

### æ¨ç†

```python
from ppdiffusers import StableDiffusionXLPipeline
from ppdiffusers import (
    AutoencoderKL,
    StableDiffusionXLPipeline,
    UNet2DConditionModel,
)
import paddle

unet_path = "your-checkpoint/unet"

pipe = StableDiffusionXLPipeline.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", paddle_dtype=paddle.float16)
vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix")
unet = UNet2DConditionModel.from_pretrained(unet_path)

prompt = "A pokemon with green eyes and red legs."
image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]
image.save("pokemon.png")
```

å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç è¿›è¡Œå¤šä¸ªcheckpointçš„æ¨ç†ï¼š
```python
from ppdiffusers import StableDiffusionXLPipeline
from ppdiffusers import (
    AutoencoderKL,
    StableDiffusionXLPipeline,
    UNet2DConditionModel,
)
import paddle
import os

dir_name = "your-checkpoints-dir"
for file_name in sorted(os.listdir(dir_name)):
    print(file_name)
    unet_path = os.path.join(dir_name, file_name)

    pipe = StableDiffusionXLPipeline.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", paddle_dtype=paddle.float16)
    vae = AutoencoderKL.from_pretrained("madebyollin/sdxl-vae-fp16-fix")
    unet = UNet2DConditionModel.from_pretrained(unet_path, subfolder="unet")

    prompt = "A pokemon with green eyes and red legs."
    image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]
    image.save("sdxl_train_pokemon_" + file_name + ".png")
```

## NPUç¡¬ä»¶è®­ç»ƒæ¨ç†

1. è¯·å…ˆå‚ç…§[PaddleCustomDevice](https://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/npu/README_cn.md)å®‰è£…NPUç¡¬ä»¶Paddle
2. ä½¿ç”¨NPUè¿›è¡Œsdxlå¾®è°ƒè®­ç»ƒå’Œæ¨ç†æ—¶å‚è€ƒå¦‚ä¸‹å‘½ä»¤è®¾ç½®ç›¸åº”çš„ç¯å¢ƒå˜é‡ï¼Œè®­ç»ƒå’Œæ¨ç†è¿è¡Œå‘½ä»¤å¯ç›´æ¥å‚ç…§ä¸Šè¿°å¾®è°ƒè®­ç»ƒå’Œæ¨ç†å‘½ä»¤ã€‚
```bash
export FLAGS_npu_storage_format=0
export FLAGS_use_stride_kernel=0
```

æ³¨æ„NPUè®­ç»ƒæš‚ä¸æ”¯æŒenable_xformers_memory_efficient_attentioné€‰é¡¹ï¼Œå¯åŠ¨å‘½ä»¤å¦‚ä¸‹:
```bash
python -u train_text_to_image_sdxl.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --pretrained_vae_model_name_or_path=$VAE_NAME \
  --dataset_name=$DATASET_NAME \
  --resolution=512 --center_crop --random_flip \
  --proportion_empty_prompts=0.2 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 --gradient_checkpointing \
  --max_train_steps=10000 \
  --learning_rate=1e-06 --lr_scheduler="constant" --lr_warmup_steps=0 \
  --mixed_precision="fp16" \
  --report_to="wandb" \
  --validation_prompt="a cute Sundar Pichai creature" --validation_epochs 5 \
  --checkpointing_steps=5000 \
  --output_dir="sdxl-pokemon-model"
```


## Stable Diffusion XL (SDXL) LoRA è®­ç»ƒç¤ºä¾‹

Low-Rank Adaptation of Large Language Models æœ€åˆç”± Microsoft åœ¨ [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) by *Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen* æå‡ºã€‚

ç®€è€Œè¨€ä¹‹ï¼ŒLoRA å…è®¸é€šè¿‡å‘ç°æœ‰æƒé‡æ·»åŠ ä¸€å¯¹ç§©åˆ†è§£çŸ©é˜µæ¥è°ƒæ•´é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¹¶**ä»…**è®­ç»ƒè¿™äº›æ–°æ·»åŠ çš„æƒé‡ã€‚è¿™æœ‰å‡ ä¸ªä¼˜ç‚¹ï¼š

- ä»¥å‰çš„é¢„è®­ç»ƒæƒé‡è¢«ä¿æŒå†»ç»“ï¼Œå› æ­¤æ¨¡å‹ä¸å®¹æ˜“é­å— [ç¾éš¾æ€§é—å¿˜](https://www.pnas.org/doi/10.1073/pnas.1611835114)ã€‚
- ç§©åˆ†è§£çŸ©é˜µçš„å‚æ•°è¿œå°‘äºåŸå§‹æ¨¡å‹ï¼Œè¿™æ„å‘³ç€è®­ç»ƒåçš„ LoRA æƒé‡å¾ˆè½»ä¾¿ã€‚
- LoRA æ³¨æ„åŠ›å±‚å…è®¸é€šè¿‡ `scale` å‚æ•°æ§åˆ¶æ¨¡å‹é€‚åº”æ–°è®­ç»ƒå›¾åƒçš„ç¨‹åº¦ã€‚

[cloneofsimo](https://github.com/cloneofsimo) æ˜¯ç¬¬ä¸€ä¸ªå°è¯•ä¸º Stable Diffusion åœ¨ä¸€ä¸ªæµè¡Œçš„ [lora](https://github.com/cloneofsimo/lora) GitHub ä»“åº“ä¸­è¿›è¡Œ LoRA è®­ç»ƒçš„äººã€‚

ä½¿ç”¨ LoRAï¼Œå¯ä»¥åœ¨æ¶ˆè´¹çº§ GPU ä¸Šå¾®è°ƒ Stable Diffusion è‡ªå®šä¹‰å›¾åƒ-æ ‡é¢˜å¯¹æ•°æ®é›†ï¼Œæ¯”å¦‚ Tesla T4, Tesla V100ã€‚

### è®­ç»ƒ

é¦–å…ˆï¼Œä½ éœ€è¦æŒ‰ç…§[å®‰è£…éƒ¨åˆ†](#å®‰è£…ä¾èµ–é¡¹)ä¸­è§£é‡Šçš„è®¾ç½®å¼€å‘ç¯å¢ƒã€‚ç¡®ä¿è®¾ç½®äº† `MODEL_NAME` å’Œ `DATASET_NAME` ç¯å¢ƒå˜é‡ï¼Œä»¥åŠå¯é€‰çš„ `VAE_NAME` å˜é‡ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [Stable Diffusion XL 1.0-base](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) å’Œ [Pokemons æ•°æ®é›†](https://huggingface.co/datasets/lambdalabs/naruto-blip-captions)ã€‚

**___æ³¨ï¼šé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®šæœŸç”Ÿæˆæ ·æœ¬å›¾åƒæ¥ç›‘æ§è®­ç»ƒè¿›åº¦éå¸¸æœ‰ç”¨ã€‚[Weights and Biases](https://docs.wandb.ai/quickstart) æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥è½»æ¾åœ°åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æŸ¥çœ‹ç”Ÿæˆçš„å›¾åƒã€‚ä½ éœ€è¦åšçš„å°±æ˜¯åœ¨è®­ç»ƒå‰è¿è¡Œ `pip install wandb`ï¼Œä»¥è‡ªåŠ¨è®°å½•å›¾åƒã€‚___**

```bash
export MODEL_NAME="stabilityai/stable-diffusion-xl-base-1.0"
export VAE_NAME="madebyollin/sdxl-vae-fp16-fix"
export DATASET_NAME="lambdalabs/naruto-blip-captions"

export HF_ENDPOINT=https://hf-mirror.com
export FLAGS_conv_workspace_size_limit=4096
```


ç°åœ¨æˆ‘ä»¬å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼

```bash
python -u train_text_to_image_lora_sdxl.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --pretrained_vae_model_name_or_path=$VAE_NAME \
  --dataset_name=$DATASET_NAME --caption_column="text" \
  --resolution=1024 --random_flip \
  --train_batch_size=1 \
  --num_train_epochs=2 --checkpointing_steps=500 \
  --learning_rate=1e-04 --lr_scheduler="constant" --lr_warmup_steps=0 \
  --mixed_precision="fp16" \
  --seed=42 \
  --output_dir="sd-pokemon-model-lora-sdxl" \
  --validation_prompt="cute dragon creature" --report_to="wandb"
```

ä¸Šè¿°å‘½ä»¤è¿˜å°†åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­æ‰§è¡Œæ¨ç†ï¼Œå¹¶å°†ç»“æœè®°å½•åˆ° Weights and Biasesã€‚

**æ³¨é‡Š**ï¼š

* ä¼—æ‰€å‘¨çŸ¥ï¼ŒSDXLçš„VAEå­˜åœ¨æ•°å€¼ä¸ç¨³å®šæ€§é—®é¢˜ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬è¿˜æš´éœ²äº†ä¸€ä¸ª CLI å‚æ•°ï¼Œå³ `--pretrained_vae_model_name_or_path`ï¼Œè®©ä½ æŒ‡å®šæ›´å¥½çš„VAEçš„ä½ç½®ï¼ˆä¾‹å¦‚[è¿™ä¸ª](https://huggingface.co/madebyollin/sdxl-vae-fp16-fix)ï¼‰ã€‚
* ä¸æ”¯æŒ`--use_8bit_adam`



### å¾®è°ƒæ–‡æœ¬ç¼–ç å™¨å’Œ UNet

è„šæœ¬è¿˜å…è®¸ä½ å¾®è°ƒ `text_encoder` ä»¥åŠ `unet`ã€‚

ğŸš¨ è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨éœ€è¦é¢å¤–çš„å†…å­˜ã€‚

å°† `--train_text_encoder` å‚æ•°ä¼ é€’ç»™è®­ç»ƒè„šæœ¬ä»¥å¯ç”¨å¾®è°ƒ `text_encoder` å’Œ `unet`ï¼š

```bash
python -u train_text_to_image_lora_sdxl.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --dataset_name=$DATASET_NAME --caption_column="text" \
  --resolution=1024 --random_flip \
  --train_batch_size=1 \
  --num_train_epochs=2 --checkpointing_steps=500 \
  --learning_rate=1e-04 --lr_scheduler="constant" --lr_warmup_steps=0 \
  --seed=42 \
  --output_dir="sd-pokemon-model-lora-sdxl-txt" \
  --train_text_encoder \
  --validation_prompt="cute dragon creature" --report_to="wandb"
```

### æ¨ç†

ä¸€æ—¦ä½ ä½¿ç”¨ä¸Šé¢çš„å‘½ä»¤è®­ç»ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œæ¨ç†å¯ä»¥ç®€å•åœ°ä½¿ç”¨ `StableDiffusionXLPipeline` åœ¨åŠ è½½è®­ç»ƒå¥½çš„ LoRA æƒé‡åè¿›è¡Œã€‚é€šè¿‡ä¿®æ”¹æ¨ç†è„šæœ¬ä¸­çš„model_pathå˜é‡ï¼Œå¯ä»¥ä¼ é€’éœ€è¦åŠ è½½çš„ LoRA è®­ç»ƒæƒé‡ï¼Œåœ¨è¿™ä¸ªæ¡ˆä¾‹ä¸­ï¼Œæ˜¯ `sd-pokemon-model-lora-sdxl`ã€‚

```python
from ppdiffusers import StableDiffusionXLPipeline
import paddle

model_path = "takuoko/sd-pokemon-model-lora-sdxl"
pipe = StableDiffusionXLPipeline.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", paddle_dtype=paddle.float16)
pipe.load_lora_weights(model_path)

prompt = "A pokemon with green eyes and red legs."
image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]
image.save("pokemon.png")
```

å¦‚æœæƒ³è¿›è¡Œå¤šä¸ªcheckpointçš„æ¨ç†ï¼Œä½ å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç ã€‚
```python
# multi image
from ppdiffusers import StableDiffusionXLPipeline
import paddle
import os

dir_name = "your-checkpoints-path/sd-pokemon-model-lora-sdxl/"
for file_name in sorted(os.listdir(dir_name)):
    if 'checkpoint' not in file_name:
        continue
    print(file_name)
    model_path = os.path.join(dir_name, file_name)
    pipe = StableDiffusionXLPipeline.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", paddle_dtype=paddle.float16)
    pipe.load_lora_weights(model_path)

    prompt = "A pokemon with green eyes and red legs."
    image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]
    image.save("pokemon_" + file_name + ".png")
```

## NPUç¡¬ä»¶è®­ç»ƒ
1. è¯·å…ˆå‚ç…§[PaddleCustomDevice](https://github.com/PaddlePaddle/PaddleCustomDevice/blob/develop/backends/npu/README_cn.md)å®‰è£…NPUç¡¬ä»¶Paddle
2. ä½¿ç”¨NPUè¿›è¡ŒLoRAè®­ç»ƒå’Œæ¨ç†æ—¶å‚è€ƒå¦‚ä¸‹å‘½ä»¤è®¾ç½®ç›¸åº”çš„ç¯å¢ƒå˜é‡ï¼Œè®­ç»ƒå’Œæ¨ç†è¿è¡Œå‘½ä»¤å¯ç›´æ¥å‚ç…§ä¸Šè¿°LoRAè®­ç»ƒå’Œæ¨ç†å‘½ä»¤ã€‚
```bash
export FLAGS_npu_storage_format=0
export FLAGS_use_stride_kernel=0
export FLAGS_npu_scale_aclnn=True
export FLAGS_allocator_strategy=auto_growth
```
